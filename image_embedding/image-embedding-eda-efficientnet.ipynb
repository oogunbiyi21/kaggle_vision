{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-07-25T21:32:50.825244Z","iopub.execute_input":"2022-07-25T21:32:50.825693Z","iopub.status.idle":"2022-07-25T21:32:50.831796Z","shell.execute_reply.started":"2022-07-25T21:32:50.825656Z","shell.execute_reply":"2022-07-25T21:32:50.830729Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom math import ceil\nimport os\nimport random\nimport matplotlib.pylab as plt\nimport plotly.express as px\nfrom zipfile import ZipFile\nfrom PIL import Image, ImageEnhance; Image.MAX_IMAGE_PIXELS = 5_000_000_000\n\nfrom sklearn.decomposition import PCA\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense,MaxPooling2D, MaxPool2D, Conv2D,Flatten,Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:50.843106Z","iopub.execute_input":"2022-07-25T21:32:50.844315Z","iopub.status.idle":"2022-07-25T21:32:50.853851Z","shell.execute_reply.started":"2022-07-25T21:32:50.844269Z","shell.execute_reply":"2022-07-25T21:32:50.852592Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"os.path.abspath(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:50.857078Z","iopub.execute_input":"2022-07-25T21:32:50.857797Z","iopub.status.idle":"2022-07-25T21:32:50.867963Z","shell.execute_reply.started":"2022-07-25T21:32:50.857749Z","shell.execute_reply":"2022-07-25T21:32:50.867071Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"import random\n\n\nlist_of_categories = os.listdir('/kaggle/input/imagenetmini-1000/imagenet-mini/train/')\n\nnumber_of_categories = len(list_of_categories)\n\n# sample_category = list_of_categories[random.choice(range(number_of_categories))]\nsample_category = \"n02093647\" # Dogs\n\nprint(sample_category)\n\nsample_photos_list = os.listdir('/kaggle/input/imagenetmini-1000/imagenet-mini/train/{}'.format(sample_category))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:50.869577Z","iopub.execute_input":"2022-07-25T21:32:50.870374Z","iopub.status.idle":"2022-07-25T21:32:50.890407Z","shell.execute_reply.started":"2022-07-25T21:32:50.870345Z","shell.execute_reply":"2022-07-25T21:32:50.889560Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# Plotting samples\n\nplt.figure(figsize=(20, 10))\n\nplt.subplot(2, 2, 1)\nsample_photo_filename_1 = random.choice(sample_photos_list)\nimage_1 = load_img('/kaggle/input/imagenetmini-1000/imagenet-mini/train/{}/{}'.format(sample_category, sample_photo_filename_1))\nplt.imshow(image_1)\n\nplt.subplot(2, 2, 2)\nsample_photo_filename_2 = random.choice(sample_photos_list)\nimage_2 = load_img('/kaggle/input/imagenetmini-1000/imagenet-mini/train/{}/{}'.format(sample_category, sample_photo_filename_2))\nplt.imshow(image_2)\n\nplt.axis('off')\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:50.891980Z","iopub.execute_input":"2022-07-25T21:32:50.892573Z","iopub.status.idle":"2022-07-25T21:32:51.245614Z","shell.execute_reply.started":"2022-07-25T21:32:50.892542Z","shell.execute_reply":"2022-07-25T21:32:51.244335Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# Pixel analysis\n\nsample_photo_filename_3 = random.choice(sample_photos_list)\nimage_3 = plt.imread('/kaggle/input/imagenetmini-1000/imagenet-mini/train/{}/{}'.format(sample_category, sample_photo_filename_3))\n\nplt.imshow(image_3, cmap='gray')\nplt.colorbar()\n# plt.title('Dog Image')\n\nprint(\"Width: {} pixels, Height: {} pixels\".format(image_3.shape[0], image_3.shape[1]))\nprint(\"Max pixel value: {}, Min pixel value: {}\".format(image_3.max(), image_3.min()))\nprint(\"Mean pixel value: {}, Standard Deviation: {}\".format(image_3.mean(), image_3.std()))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:51.247923Z","iopub.execute_input":"2022-07-25T21:32:51.249132Z","iopub.status.idle":"2022-07-25T21:32:51.583844Z","shell.execute_reply.started":"2022-07-25T21:32:51.249085Z","shell.execute_reply":"2022-07-25T21:32:51.582630Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# Pixel distribution\n\nimport seaborn as sns\n\nsns.distplot(image_3.ravel(),\n             label=\"Pixel Mean {} & Standard Deviation {}\".format(np.mean(image_3),np.std(image_3)), \n             kde=False)\nplt.legend(loc='upper right')\nplt.title('Distribution of Pixel Intensities in the Image')\nplt.xlabel('Pixel Intensity')\nplt.ylabel('# Pixels in Image')","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:51.585561Z","iopub.execute_input":"2022-07-25T21:32:51.585876Z","iopub.status.idle":"2022-07-25T21:32:51.864194Z","shell.execute_reply.started":"2022-07-25T21:32:51.585847Z","shell.execute_reply":"2022-07-25T21:32:51.863104Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# Credit: https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2\ndef img2np(path, list_of_filename, size = (64, 64)):\n    # iterating through each file\n    for fn in list_of_filename:\n        fp = path + fn\n        current_image = image.load_img(fp, target_size = size, \n                                       color_mode = 'grayscale')\n        # covert image to a matrix\n        img_ts = image.img_to_array(current_image)\n        # turn that into a vector / 1D array\n        img_ts = [img_ts.ravel()]\n        try:\n            # concatenate different images\n            full_mat = np.concatenate((full_mat, img_ts))\n        except UnboundLocalError: \n            # if not assigned yet, assign one\n            full_mat = img_ts\n    return full_mat\n\n# run it on our folders\ndog_images_matrix = img2np('/kaggle/input/imagenetmini-1000/imagenet-mini/train/{}/'.format(sample_category), sample_photos_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:51.867024Z","iopub.execute_input":"2022-07-25T21:32:51.867383Z","iopub.status.idle":"2022-07-25T21:32:52.119323Z","shell.execute_reply.started":"2022-07-25T21:32:51.867353Z","shell.execute_reply":"2022-07-25T21:32:52.118231Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# Credit: https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2\ndef eigenimages(full_mat, title, n_comp = 0.7, size = (64, 64)):\n    # fit PCA to describe n_comp * variability in the class\n    pca = PCA(n_components = n_comp, whiten = True)\n    pca.fit(full_mat)\n    print('Number of PC: ', pca.n_components_)\n    return pca\n  \ndef plot_pca(pca, size = (64, 64)):\n    # plot eigenimages in a grid\n    n = pca.n_components_\n    fig = plt.figure(figsize=(8, 8))\n    r = int(n**.5)\n    c = ceil(n/ r)\n    for i in range(n):\n        ax = fig.add_subplot(r, c, i + 1, xticks = [], yticks = [])\n        ax.imshow(pca.components_[i].reshape(size), \n                  cmap='Greys_r')\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:52.120704Z","iopub.execute_input":"2022-07-25T21:32:52.121046Z","iopub.status.idle":"2022-07-25T21:32:52.131512Z","shell.execute_reply.started":"2022-07-25T21:32:52.121013Z","shell.execute_reply":"2022-07-25T21:32:52.130133Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"plot_pca(eigenimages(dog_images_matrix, 'Dogs'))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:52.132952Z","iopub.execute_input":"2022-07-25T21:32:52.134071Z","iopub.status.idle":"2022-07-25T21:32:52.615544Z","shell.execute_reply.started":"2022-07-25T21:32:52.134008Z","shell.execute_reply":"2022-07-25T21:32:52.614354Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Building data generators for easier data augmentation. Validation generator has samplewise settings set to False because this information will not be available during test time\n\ntrain_image_generator = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    samplewise_center=True,\n    samplewise_std_normalization=True\n)\n\nval_image_generator = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    samplewise_center=False,\n    samplewise_std_normalization=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:52.617270Z","iopub.execute_input":"2022-07-25T21:32:52.618198Z","iopub.status.idle":"2022-07-25T21:32:52.626753Z","shell.execute_reply.started":"2022-07-25T21:32:52.618152Z","shell.execute_reply":"2022-07-25T21:32:52.625579Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Setting data sources\n\ntrain = train_image_generator.flow_from_directory(\"/kaggle/input/imagenetmini-1000/imagenet-mini/train\", \n                                            batch_size=8, \n                                            shuffle=True, \n                                            class_mode='binary',\n                                            target_size=(320, 320))\n\nvalidation = val_image_generator.flow_from_directory(\"/kaggle/input/imagenetmini-1000/imagenet-mini/val\", \n                                                batch_size=1, \n                                                shuffle=False, \n                                                class_mode='binary',\n                                                target_size=(320, 320))","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:52.627970Z","iopub.execute_input":"2022-07-25T21:32:52.629139Z","iopub.status.idle":"2022-07-25T21:32:55.569304Z","shell.execute_reply.started":"2022-07-25T21:32:52.629095Z","shell.execute_reply":"2022-07-25T21:32:55.567785Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# From https://www.kaggle.com/code/dschettler8845/guie-a-better-tensorflow-example-baseline-model\n\ndef build_guie_model(wt_path, tf_keras_model_fn):\n    _inputs = tf.keras.layers.Input(shape=(None,None,3), batch_size=1, dtype=tf.uint8, name=\"inputs\")\n    _bb = tf_keras_model_fn(include_top=False, weights=wt_path)\n    x = tf.keras.layers.GlobalAveragePooling2D()(_bb(_inputs))\n    x = tf.keras.layers.Reshape((-1,1))(x)\n    x = tf.keras.layers.AveragePooling1D(22)(x)\n    _output_1 = tf.keras.layers.Reshape((-1,), name=\"embedding\")(x)\n    _output_2 = tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x), name=\"embedding_norm\")(_output_1)    \n    return tf.keras.Model(inputs=_inputs, outputs=[_output_1, _output_2])\n\nIMAGENET_WEIGHTS = \"imagenet\"\nTF_KERAS_MODEL_FN = tf.keras.applications.EfficientNetB2\n\nguie_model = build_guie_model(IMAGENET_WEIGHTS, TF_KERAS_MODEL_FN)\nguie_model.summary()\n\nos.makedirs(\"/kaggle/models\", exist_ok=True)\nguie_model.save(\"/kaggle/models\")","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:32:55.571884Z","iopub.execute_input":"2022-07-25T21:32:55.573015Z","iopub.status.idle":"2022-07-25T21:33:58.578926Z","shell.execute_reply.started":"2022-07-25T21:32:55.572964Z","shell.execute_reply":"2022-07-25T21:33:58.577593Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\nwith ZipFile('/kaggle/submission.zip','w') as zip:           \n  zip.write('/kaggle/models/saved_model.pb', arcname='saved_model.pb') \n  zip.write('/kaggle/models/variables/variables.data-00000-of-00001', arcname='variables/variables.data-00000-of-00001') \n  zip.write('/kaggle/models/variables/variables.index', arcname='variables/variables.index') ","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:33:58.608686Z","iopub.execute_input":"2022-07-25T21:33:58.609181Z","iopub.status.idle":"2022-07-25T21:33:58.819366Z","shell.execute_reply.started":"2022-07-25T21:33:58.609140Z","shell.execute_reply":"2022-07-25T21:33:58.818435Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"saved_model_path = \"/kaggle/models\"\nimage_path       =  \"/kaggle/input/imagenetmini-1000/imagenet-mini/val/n03976657/ILSVRC2012_val_00043517.JPEG\"\n\n# Model loading.\nmodel = tf.saved_model.load(saved_model_path)\nembedding_fn = model.signatures[\"serving_default\"]\n\n# Load image and extract its embedding.\nimage_tensor = tf.convert_to_tensor(np.array(Image.open(image_path).convert(\"RGB\")))\nexpanded_tensor = tf.expand_dims(image_tensor, axis=0)\nembedding = embedding_fn(expanded_tensor)[\"embedding_norm\"]\n\nprint(embedding)","metadata":{"execution":{"iopub.status.busy":"2022-07-25T21:33:58.820736Z","iopub.execute_input":"2022-07-25T21:33:58.821547Z","iopub.status.idle":"2022-07-25T21:34:21.910475Z","shell.execute_reply.started":"2022-07-25T21:33:58.821514Z","shell.execute_reply":"2022-07-25T21:34:21.909467Z"},"trusted":true},"execution_count":115,"outputs":[]}]}